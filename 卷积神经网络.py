#
# 对CIFAR-10数据集的分类是机器学习中的一个公开的基准测试问题，其任务是对一组大小为32x32的RGB图像进行分类
# 这些图像涵盖了10个类别：飞机，汽车，鸟，猫，鹿，狗，青蛙，马，船以及卡车
#
# 目标
# 本教程的目标是建立一个用于识别图像的相对较小的卷积神经网络，在这过程中
#   着重建立一个规范的网络组织结构，训练并进行评估
#   为建立更大规模更加复杂的模型提供一个范例
# 选择CIFAR-10是因为它的复杂程度足以用来检验TensorFlow中的大部分功能，并可将其扩展为更大的模型
# 同时，由于模型较小所以训练速度很快，所以比较适合用来测试新的想法检验新的技术

#
# 本教程重点
# CIFAR-10教程演示了再TensorFlow上构建更大更复杂模型的几个重要内容：
# 相关核心数学对象，如卷积，修正线性激活，最大池化以及局部响应归一化
# 训练过程中一些网络行为的可视化，这些行为包括输入图像，损失情况，网络行为的分布情况以及梯度
# 算法学习参数的移动平均值得计算函数，以及在评估阶段使用这些平均值提高预测性能
# 实现了一种机制，使得学习率随着时间推移而递减
# 为输入数据设计预存取队列，将磁盘延迟和高开销的图像预处理操作与模型分离开来处理
# 我们也提供了模型的多GPU版本，用来表明：
# 可以配置模型后使其在多个GPU上并行训练
# 可在多个GPU之间共享和更新变量值

#
# 模型架构
# 本教程中的模型时一个多层架构，由卷积层和非线性层（nonlinearities）交替多次排列后构成
# 这些层最终通过全连接层对接到softmax分类器上

#
# CIFAR-10模型
# CIFAR-10模型通过下面模块构造训练图可以最大限度的提高代码复用率：
# 模型输入：包括inputs(),distorted_inputs()等，分别用来读取CIFAR图像并进行预处理，做为后续评估和训练的输入
# 模型预测：包括inference()等，用于进行统计计算，比如在提供的图像进行分类
# 模型训练：包括loss()和train()等，用于计算损失，计算梯度，进行变量更新以呈现最终结果

# 模型输入
# 模型的输入时通过input()和distorted_inputs()函数建立起来的,这两个函数从CIFAR-10二进制文件中读取文件，
# 由于每个图片的存储字节数是固定的，因此可以使用tf.FixedLengthRecordReader函数
# 图片文件的处理流程如下：
#   图片会被统一裁剪到24x24像素大小，裁剪中央区域用于评估或随机裁剪用于训练
#   图片会进行近似的白化处理，使得模型对图片的动态范围变化不敏感
# 对于训练，我们采用另外一系列随机变化的方法来认为增加数据集的大小：
#   对图像进行随机地左右翻转
#   随机变化图像的亮度
#   随机变化图像的对比度

#
# 模型预测
# 模型的预测流程由inference()构造，该函数会添加必要的操作步骤用于计算预测值的logits，其对应的模型组织方式如下：
# Layer名称           描述
# conv_1             实现卷积以及rectified linear activation
# pool_1             max pooling
# norm_1             局部响应归一化
# conv_2             卷积和rectified linear activation
# norm_2             局部响应归一化
# pool_2             max pooling
# local_3            基于修正线性激活的全连接层
# local_4            基于修正线性激活的全连接层
# softmax_linear     进行线性变换以输出logits

#
# 模型训练
# 训练一个可进行N维分类的网络的常用方法是使用多项式逻辑回归，有被称为softmax回归。
# softmax回归在网络输出层附加了一个softmax nonlinearity，并且计算归一化的预测值和label的1-hot encoding的交叉熵
# 在正则化的过程中，我们会对所有学习变量应用权重衰减损失。模型的目标函数时求交叉熵损失和所有权重衰减项的和，loss函数返回值就是
# train()函数会添加一些操作使得目标函数最小化，这些操作包括计算梯度，更新学习变量，它最终会返回一个用于对一批图像执行所有计算的操作步骤


